{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.14",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "sourceId": 29550,
          "sourceType": "datasetVersion",
          "datasetId": 23079
        },
        {
          "sourceId": 399170,
          "sourceType": "datasetVersion",
          "datasetId": 177084
        },
        {
          "sourceId": 2184214,
          "sourceType": "datasetVersion",
          "datasetId": 1311225
        },
        {
          "sourceId": 2702383,
          "sourceType": "datasetVersion",
          "datasetId": 1646010
        }
      ],
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "name": "American Sign Language",
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PrasannaPulakurthi/ASL_Classification/blob/main/American_Sign_Language.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "VBmATwhYR7le"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES\n",
        "# TO THE CORRECT LOCATION (/kaggle/input) IN YOUR NOTEBOOK,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "import os\n",
        "import sys\n",
        "from tempfile import NamedTemporaryFile\n",
        "from urllib.request import urlopen\n",
        "from urllib.parse import unquote, urlparse\n",
        "from urllib.error import HTTPError\n",
        "from zipfile import ZipFile\n",
        "import tarfile\n",
        "import shutil\n",
        "\n",
        "CHUNK_SIZE = 40960\n",
        "DATA_SOURCE_MAPPING = 'asl-alphabet:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F23079%2F29550%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20241009%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20241009T025616Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D8030a27c3dbb036954562a559e4321435a99a7fba5cd026fab1bfcb19caea2784d15c2809fb34b33493c4a472222a1720deb462058485eb4a57e9c8d74b2fa516b5b9873d460fd8c1accebcd3e935eb5931c964e38d0ab11b264b9d316c1382f397ff233cefea8f595a482d39253ca980050e42a4e2bb0b557bc5c15590bb2a29559fc1ff1f047daad7cceb7f604b9e8f6d3b39d547347ffe9d39ef38590ff0efe87162688478c89b016fa21c1df557fe6d0c712ea5f4998ab921140f4be49fa35348d7e4ee377f1e6c4ebed24ec870b32debe26ee664b51d51c55c67b108c65fa4b028906866b5bace3d233a1d399712b6bee8c3d4ab01d4f788349b1717ff5,asl-dataset:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F177084%2F399170%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20241009%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20241009T025616Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D8c8b6ebaabaf6fb781040a29f150cc9606166f74235a21df984109d760b7f630bc2751e27a3fbb2fc149ae222699a3ab246031306b93e341f0573066152f930b91455007bcc4ba153663e83a5253803163cc7c95a7e8e21ef650e3f59a565baab095d41b9908addc1154276e1911796d31936c6546d0cc6f958d57940ca81ae50aab779960a2218856c0d005ce0204e44750193734bb488c06606e97584528c55217b4f3054c5ca0af87c39b634c9bf160b79661c3f763db521cb0b7eb43f873436835b049545e4372c2b1ecd708d96ba529c48a9a9a4371192e66a0a3f2e00a28956a6ce7e783749a9f3d8907a7232ccf978755565f2518d9c6644ec3e0042d,american-sign-language:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F1311225%2F2184214%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20241009%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20241009T025616Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D8d97df66a792fdf511263039742e6906cfb9a129815d7a7f4bfea4a7832cd9c1e464bce3e6d41e1cbb1cf2d125ab3fccc734ea1f6cbae43ec4f69f7bdc34bba4561bf2d5d929a6a557f97ab936881187f1bdae06adf092524fda86cccfd5f196af7638dad3726eb20a9cecc7eb8fd8d7bf1ab44149027594bff37eaa3a3914a02a8e67cf6c160a8a246e783543218c6433585cd3a5a419466fdbb1217a615096d8d584d37b395ba7c0672ef71d06de988e08394a747e490f3978bcf47cf2b0e1a2697cce1987e986d1e8bab0bc238faf1c8e62983513ba18340dd64d9400fc67ac96cc1921bca016a5f8d30831b4c3b4ecb8ff510e5f40ed54791d43641e4081,aslamerican-sign-language-aplhabet-dataset:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F1646010%2F2702383%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20241009%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20241009T025616Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D7ddbe74b9fc24209e6a304cc2b240deeaafb67b791e137d13b3b2e494ac10d3f0eeb26a0a99cb47e08ea4102075d2f7a25fea708c7eb0ad032c48ab37d901e092692472ef3ffb2c44b57953dd1fc5e695231ce8011e9a96217813e4320ff5bcf69b645b8f3b9b0e795ff8ccac2f8056fd1fc41acbc13f2fbeb92959a3306318b9cc5cc70a90a9a6d74e0045329dccf879142de2d69e1b00a649c1e6a60d9381dabcd8714d8df17bfe852fb218267e6d4efeea250b47c9186dd61c75fd19ac5be9109474ce068d1da379803c7b64bf3d20d228b39cc64581081ab7f5d110cf60680a962a01f47df325bd4cea6a08599831106a8b1eefc43a11a5cea67f95db68e'\n",
        "\n",
        "KAGGLE_INPUT_PATH='/kaggle/input'\n",
        "KAGGLE_WORKING_PATH='/kaggle/working'\n",
        "KAGGLE_SYMLINK='kaggle'\n",
        "\n",
        "!umount /kaggle/input/ 2> /dev/null\n",
        "shutil.rmtree('/kaggle/input', ignore_errors=True)\n",
        "os.makedirs(KAGGLE_INPUT_PATH, 0o777, exist_ok=True)\n",
        "os.makedirs(KAGGLE_WORKING_PATH, 0o777, exist_ok=True)\n",
        "\n",
        "try:\n",
        "  os.symlink(KAGGLE_INPUT_PATH, os.path.join(\"..\", 'input'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "try:\n",
        "  os.symlink(KAGGLE_WORKING_PATH, os.path.join(\"..\", 'working'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "\n",
        "for data_source_mapping in DATA_SOURCE_MAPPING.split(','):\n",
        "    directory, download_url_encoded = data_source_mapping.split(':')\n",
        "    download_url = unquote(download_url_encoded)\n",
        "    filename = urlparse(download_url).path\n",
        "    destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)\n",
        "    try:\n",
        "        with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:\n",
        "            total_length = fileres.headers['content-length']\n",
        "            print(f'Downloading {directory}, {total_length} bytes compressed')\n",
        "            dl = 0\n",
        "            data = fileres.read(CHUNK_SIZE)\n",
        "            while len(data) > 0:\n",
        "                dl += len(data)\n",
        "                tfile.write(data)\n",
        "                done = int(50 * dl / int(total_length))\n",
        "                sys.stdout.write(f\"\\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded\")\n",
        "                sys.stdout.flush()\n",
        "                data = fileres.read(CHUNK_SIZE)\n",
        "            if filename.endswith('.zip'):\n",
        "              with ZipFile(tfile) as zfile:\n",
        "                zfile.extractall(destination_path)\n",
        "            else:\n",
        "              with tarfile.open(tfile.name) as tarfile:\n",
        "                tarfile.extractall(destination_path)\n",
        "            print(f'\\nDownloaded and uncompressed: {directory}')\n",
        "    except HTTPError as e:\n",
        "        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')\n",
        "        continue\n",
        "    except OSError as e:\n",
        "        print(f'Failed to load {download_url} to path {destination_path}')\n",
        "        continue\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "zNMiGAZWNLYk",
        "outputId": "459c36e3-3f38-404f-ac27-1ab00e7edbc5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading asl-alphabet, 1100887034 bytes compressed\n",
            "[=========                                         ] 205332480 bytes downloaded"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-9c3187612bc5>\u001b[0m in \u001b[0;36m<cell line: 39>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     53\u001b[0m                 \u001b[0mdone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m50\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mdl\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m                 \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m                 \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfileres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCHUNK_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.zip'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/iostream.py\u001b[0m in \u001b[0;36mflush\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    348\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpub_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mschedule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m                 \u001b[0;31m# and give a timeout to avoid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 350\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mevt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    351\u001b[0m                     \u001b[0;31m# write directly to __stderr__ instead of warning because\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m                     \u001b[0;31m# if this is happening sys.stderr may be the problem.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    605\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    606\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 607\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    608\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    322\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "execution_count": 1
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Libraries\n",
        "\n",
        "# Warning\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# Main\n",
        "import os\n",
        "import glob\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import gc\n",
        "import string\n",
        "import time\n",
        "import random\n",
        "import imutils\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "tqdm.pandas()\n",
        "\n",
        "# Visualization\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly\n",
        "import plotly.graph_objects as go\n",
        "import plotly.express as px\n",
        "from plotly.subplots import make_subplots\n",
        "from sklearn.manifold import TSNE\n",
        "\n",
        "# Model\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array, array_to_img\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
        "from keras.models import load_model, Model\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "execution": {
          "iopub.status.busy": "2024-09-24T16:08:31.171487Z",
          "iopub.execute_input": "2024-09-24T16:08:31.171901Z",
          "iopub.status.idle": "2024-09-24T16:08:44.85601Z",
          "shell.execute_reply.started": "2024-09-24T16:08:31.171862Z",
          "shell.execute_reply": "2024-09-24T16:08:44.854944Z"
        },
        "trusted": true,
        "id": "7a1T-CGnNLYo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install imutils"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-24T16:08:03.215332Z",
          "iopub.execute_input": "2024-09-24T16:08:03.215975Z",
          "iopub.status.idle": "2024-09-24T16:08:17.708763Z",
          "shell.execute_reply.started": "2024-09-24T16:08:03.215933Z",
          "shell.execute_reply": "2024-09-24T16:08:17.70785Z"
        },
        "trusted": true,
        "id": "VSLzSeCUNLYo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Configuration\n",
        "class CFG:\n",
        "    batch_size = 64\n",
        "    img_height = 64\n",
        "    img_width = 64\n",
        "    epochs = 15\n",
        "    num_classes = 36\n",
        "    img_channels = 1\n",
        "\n",
        "def seed_everything(seed: int):\n",
        "    random.seed(seed)\n",
        "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    tf.random.set_seed(seed)\n",
        "\n",
        "\n",
        "\n",
        "# Directory path\n",
        "TRAIN_PATH = \"/kaggle/input/aslamerican-sign-language-aplhabet-dataset/ASL_Alphabet_Dataset/asl_alphabet_train\"\n",
        "\n",
        "# Labels\n",
        "labels = []\n",
        "\n",
        "# Get the folder names (which represent the labels)\n",
        "label_folders = os.listdir(TRAIN_PATH)\n",
        "\n",
        "# Append the label names from folder names to the labels list\n",
        "labels.extend(label_folders)\n",
        "\n",
        "print(labels)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-24T16:08:44.857573Z",
          "iopub.execute_input": "2024-09-24T16:08:44.858186Z",
          "iopub.status.idle": "2024-09-24T16:08:44.888323Z",
          "shell.execute_reply.started": "2024-09-24T16:08:44.858151Z",
          "shell.execute_reply": "2024-09-24T16:08:44.887443Z"
        },
        "trusted": true,
        "id": "ZhycCt8hNLYp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Create Metadata\n",
        "list_path = []\n",
        "list_labels = []\n",
        "for label in labels:\n",
        "    label_path = os.path.join(TRAIN_PATH, label, \"*\")\n",
        "    image_files = glob.glob(label_path)\n",
        "\n",
        "    sign_label = [label] * len(image_files)\n",
        "\n",
        "    list_path.extend(image_files)\n",
        "    list_labels.extend(sign_label)\n",
        "\n",
        "metadata = pd.DataFrame({\n",
        "    \"image_path\": list_path,\n",
        "    \"label\": list_labels\n",
        "})\n",
        "\n",
        "print(metadata)\n",
        "\n",
        "\n",
        "# Split Dataset to Train 0.7, Val 0.15, and Test 0.15\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    metadata[\"image_path\"], metadata[\"label\"],\n",
        "    test_size=0.15,\n",
        "    random_state=2023,\n",
        "    shuffle=True,\n",
        "    stratify=metadata[\"label\"]\n",
        ")\n",
        "data_train = pd.DataFrame({\n",
        "    \"image_path\": X_train,\n",
        "    \"label\": y_train\n",
        "})\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    data_train[\"image_path\"], data_train[\"label\"],\n",
        "    test_size=0.15/0.70,\n",
        "    random_state=2023,\n",
        "    shuffle=True,\n",
        "    stratify=data_train[\"label\"]\n",
        ")\n",
        "data_train = pd.DataFrame({\n",
        "    \"image_path\": X_train,\n",
        "    \"label\": y_train\n",
        "})\n",
        "data_val = pd.DataFrame({\n",
        "    \"image_path\": X_val,\n",
        "    \"label\": y_val\n",
        "})\n",
        "data_test = pd.DataFrame({\n",
        "    \"image_path\": X_test,\n",
        "    \"label\": y_test\n",
        "})\n",
        "\n",
        "print(data_train)\n",
        "print(data_val)\n",
        "print(data_test)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-24T16:09:06.606778Z",
          "iopub.execute_input": "2024-09-24T16:09:06.607192Z",
          "iopub.status.idle": "2024-09-24T16:09:29.318975Z",
          "shell.execute_reply.started": "2024-09-24T16:09:06.607153Z",
          "shell.execute_reply": "2024-09-24T16:09:29.317959Z"
        },
        "trusted": true,
        "id": "XY42EpTzNLYp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Augmentation (Just Rescale)\n",
        "def data_augmentation():\n",
        "    datagen = ImageDataGenerator(\n",
        "        samplewise_center=True,\n",
        "        samplewise_std_normalization=True,\n",
        "        horizontal_flip=False,\n",
        "        rotation_range=30,\n",
        "        shear_range=0.2,\n",
        "        zoom_range=0.2,  # Zoom in and out\n",
        "        width_shift_range=0.2,  # Shift images horizontally\n",
        "        height_shift_range=0.2,  # Shift images vertically\n",
        "        brightness_range=[0.8, 1.2],  # Randomly change brightness\n",
        "        fill_mode='nearest'  # Fill in pixels with nearest value\n",
        "    )\n",
        "    # Training Dataset\n",
        "    train_generator = datagen.flow_from_dataframe(\n",
        "        data_train,\n",
        "        directory=\"./\",\n",
        "        x_col=\"image_path\",\n",
        "        color_mode='grayscale',\n",
        "        y_col=\"label\",\n",
        "        class_mode=\"categorical\",\n",
        "        batch_size=CFG.batch_size,\n",
        "        target_size=(CFG.img_height, CFG.img_width),\n",
        "    )\n",
        "\n",
        "    # Validation Dataset\n",
        "    validation_generator = datagen.flow_from_dataframe(\n",
        "        data_val,\n",
        "        directory=\"./\",\n",
        "        x_col=\"image_path\",\n",
        "        color_mode='grayscale',\n",
        "        y_col=\"label\",\n",
        "        class_mode=\"categorical\",\n",
        "        batch_size=CFG.batch_size,\n",
        "        target_size=(CFG.img_height, CFG.img_width),\n",
        "    )\n",
        "\n",
        "    # Testing Dataset\n",
        "    test_generator = datagen.flow_from_dataframe(\n",
        "        data_test,\n",
        "        directory=\"./\",\n",
        "        x_col=\"image_path\",\n",
        "        color_mode='grayscale',\n",
        "        y_col=\"label\",\n",
        "        class_mode=\"categorical\",\n",
        "        batch_size=1,\n",
        "        target_size=(CFG.img_height, CFG.img_width),\n",
        "        shuffle=False\n",
        "    )\n",
        "\n",
        "    return train_generator, validation_generator, test_generator\n",
        "\n",
        "seed_everything(2023)\n",
        "train_generator, validation_generator, test_generator = data_augmentation()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-24T16:09:36.373188Z",
          "iopub.execute_input": "2024-09-24T16:09:36.37356Z",
          "iopub.status.idle": "2024-09-24T16:20:47.548405Z",
          "shell.execute_reply.started": "2024-09-24T16:09:36.373528Z",
          "shell.execute_reply": "2024-09-24T16:20:47.547657Z"
        },
        "trusted": true,
        "id": "mRYGmmlCNLYp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from tensorflow.keras.regularizers import l2\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
        "from tensorflow.keras.layers import Flatten, Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.regularizers import l2\n",
        "\n",
        "# Define the improved model\n",
        "model = Sequential()\n",
        "\n",
        "# First Convolutional Block\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(64, 64, 1), padding='same'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# Second Convolutional Block\n",
        "model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# Third Convolutional Block\n",
        "model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# Fourth Convolutional Block\n",
        "model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# Fifth Convolutional Block (Optional for more complexity)\n",
        "model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# Fully Connected Layers\n",
        "model.add(Flatten())\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dropout(0.5))  # Increase dropout to prevent overfitting\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "# Output Layer\n",
        "model.add(Dense(29, activation='softmax'))\n",
        "\n",
        "# Model Summary\n",
        "model.summary()\n",
        "\n",
        "\n",
        "# Visualize the model architecture\n",
        "print(tf.keras.utils.plot_model(model, to_file='custom_cnn.png', show_shapes=True))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Callbacks for early stopping and model checkpointing\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=2, restore_best_weights=True)\n",
        "checkpoint = ModelCheckpoint('custom_cnn_best_weights.keras', save_best_only=True, monitor='val_accuracy', mode='max')\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=train_generator.samples // CFG.batch_size,\n",
        "    epochs=CFG.epochs,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=validation_generator.samples // CFG.batch_size,\n",
        "    callbacks=[checkpoint]\n",
        ")\n",
        "\n",
        "# Save the trained model\n",
        "model.save('custom_cnn_sign_language5.h5')\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-24T16:22:24.365478Z",
          "iopub.execute_input": "2024-09-24T16:22:24.365883Z",
          "iopub.status.idle": "2024-09-24T18:02:20.883104Z",
          "shell.execute_reply.started": "2024-09-24T16:22:24.365846Z",
          "shell.execute_reply": "2024-09-24T18:02:20.881983Z"
        },
        "trusted": true,
        "id": "VgGSEzB8NLYq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('custom_cnn_sign_language11.h5')\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-24T18:03:10.125654Z",
          "iopub.execute_input": "2024-09-24T18:03:10.126426Z",
          "iopub.status.idle": "2024-09-24T18:03:10.234347Z",
          "shell.execute_reply.started": "2024-09-24T18:03:10.126368Z",
          "shell.execute_reply": "2024-09-24T18:03:10.233545Z"
        },
        "trusted": true,
        "id": "D_-6wp7jNLYq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plot training & validation accuracy values\n",
        "plt.figure(figsize=(12, 4))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Model Accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "\n",
        "# Plot training & validation loss values\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model Loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-24T18:21:15.82574Z",
          "iopub.execute_input": "2024-09-24T18:21:15.826662Z",
          "iopub.status.idle": "2024-09-24T18:21:16.350249Z",
          "shell.execute_reply.started": "2024-09-24T18:21:15.826605Z",
          "shell.execute_reply": "2024-09-24T18:21:16.349237Z"
        },
        "trusted": true,
        "id": "8nLHLDn_NLYq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uKUpaBHJRex4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}